{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cGAN generate LiDAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import cv2\n",
    "import copy\n",
    "import math\n",
    "import wandb\n",
    "import random\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from collections import deque\n",
    "from tqdm import tqdm, trange\n",
    "from typing import Deque, Dict, List, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153 episodes\n",
      "31 episodes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "name_corridor = ['0717_1411', \n",
    "                '0720_1129',\n",
    "                '0722_1428',\n",
    "                '0722_1437',\n",
    "                '0722_1448',\n",
    "                '0722_1500',\n",
    "                '0722_1506',\n",
    "                '0722_1510',\n",
    "                '0722_1514',\n",
    "                '0724_1101',\n",
    "                '0724_1132',\n",
    "                '0724_1204',\n",
    "                '0727_1005',\n",
    "                '0727_1027',\n",
    "                '0727_1102',\n",
    "                '0727_1435',\n",
    "                '0727_1452',\n",
    "                '0727_1510',\n",
    "                '0727_1520',\n",
    "                '0805_1108',\n",
    "                '0805_1127',\n",
    "                '0805_1147']\n",
    "\n",
    "name_parking = ['0717_1504',\n",
    "                '0720_1105',\n",
    "                '0805_1349',\n",
    "                '0805_1425']\n",
    "\n",
    "paths_corridor, paths_parking = [], []\n",
    "\n",
    "main_path = '/media/ray/intelSSD/mmdemo_train'\n",
    "dirs = os.listdir(main_path)\n",
    "dirs.sort()\n",
    "for d in dirs:\n",
    "    dirs1 = os.listdir(main_path+'/'+d)\n",
    "    dirs1.sort()\n",
    "    dirs2 = os.listdir(main_path+'/'+d+'/'+dirs1[1])\n",
    "    dirs2.sort()\n",
    "    for d2 in dirs2:\n",
    "        if any(s in d2 for s in name_corridor):\n",
    "            paths_corridor.append(main_path+'/'+d+'/'+dirs1[1]+'/'+d2)\n",
    "#             print(paths_corridor[-1])\n",
    "        elif any(s in d2 for s in name_parking):\n",
    "            paths_parking.append(main_path+'/'+d+'/'+dirs1[1]+'/'+d2)\n",
    "#             print(paths_parking[-1])\n",
    "            \n",
    "print('%d episodes'%len(paths_corridor))\n",
    "print('%d episodes'%len(paths_parking))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153/153 [00:01<00:00, 95.54it/s]\n",
      "100%|██████████| 31/31 [00:00<00:00, 96.77it/s]\n"
     ]
    }
   ],
   "source": [
    "class MMDataset(Dataset):\n",
    "    def __init__(self, paths):\n",
    "        self.transitions = []\n",
    "\n",
    "        for p in tqdm(paths):\n",
    "            with open(p, \"rb\") as f:\n",
    "                demo = pkl.load(f, encoding=\"bytes\")\n",
    "                self.transitions.extend(demo)\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        mm_scan = self.transitions[index][b'mm_scan']\n",
    "        laser_scan = self.transitions[index][b'laser_scan']\n",
    "        mm_scan = torch.Tensor(mm_scan).reshape(1,-1)\n",
    "        laser_scan = torch.Tensor(laser_scan).reshape(1,-1)\n",
    "        \n",
    "        return mm_scan, laser_scan\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.transitions)\n",
    "\n",
    "    \n",
    "batch_size = 128\n",
    "\n",
    "corridor_dataset = MMDataset(paths_corridor)\n",
    "loader_corridor = DataLoader(dataset=corridor_dataset,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    num_workers=4)\n",
    "\n",
    "parking_dataset = MMDataset(paths_parking)\n",
    "loader_parking = DataLoader(dataset=parking_dataset,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    num_workers=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_parameter = dict(\n",
    "    kernel=3,\n",
    "    stride=2,\n",
    "    padding=2,\n",
    "    deconv_dim=32,\n",
    "    deconv_channel=128,\n",
    "    adjust_linear=235,\n",
    "    epoch=500,\n",
    "    beta1=0.5,\n",
    "    learning_rate=0.0002,\n",
    "    nz=100,\n",
    "    lambda_l1=100,\n",
    ")\n",
    "class Struct:\n",
    "    def __init__(self, **entries):\n",
    "        self.__dict__.update(entries)\n",
    "config = Struct(**hyper_parameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        kernel = 3\n",
    "        stride = 2\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(1, 64, kernel_size=kernel, stride=stride),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 64, kernel_size=kernel, stride=stride),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        dim = 64*59\n",
    "        self.linear=nn.Sequential(\n",
    "            nn.Linear(dim,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,128)\n",
    "        )\n",
    "        \n",
    "#         self.n_fc1=nn.Linear(config.nz, 128)\n",
    "#         self.n_fc2=nn.Linear(128, 128)\n",
    "        \n",
    "#         self.fc_combine=nn.Linear(128*2, 128)\n",
    "        \n",
    "        self.de_fc1=nn.Sequential(\n",
    "            nn.Linear(128,config.deconv_channel*config.deconv_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.de_conv =nn.Sequential(\n",
    "            nn.ConvTranspose1d(config.deconv_channel, config.deconv_channel//2, kernel, stride=stride, padding=config.padding),\n",
    "            nn.ConvTranspose1d(config.deconv_channel//2, config.deconv_channel//4, kernel, stride=stride, padding=config.padding),\n",
    "            nn.ConvTranspose1d(config.deconv_channel//4, 1, kernel, stride=stride, padding=config.padding),\n",
    "        )\n",
    "        self.adjust_linear=nn.Sequential(\n",
    "            nn.Linear(config.adjust_linear,241),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        \n",
    "    def encoder(self,x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "    def decoder(self,x):\n",
    "        x = self.de_fc1(x)\n",
    "        x = x.view(-1, config.deconv_channel, config.deconv_dim)\n",
    "        x = self.de_conv(x)\n",
    "        x = self.adjust_linear(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "#         n = self.n_fc1(n)\n",
    "#         n = self.n_fc2(n)\n",
    "        \n",
    "#         x = torch.cat((x,n),dim=-1)\n",
    "#         x = self.fc_combine(x)\n",
    "        \n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        kernel = 3\n",
    "        stride = 2\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(2, 64, kernel_size=kernel, stride=stride),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 64, kernel_size=kernel, stride=stride),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        dim = 64*59\n",
    "        self.linear=nn.Sequential(\n",
    "            nn.Linear(dim,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "                \n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.linear(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device,  cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (conv): Sequential(\n",
       "    (0): Conv1d(1, 64, kernel_size=(3,), stride=(2,))\n",
       "    (1): ReLU()\n",
       "    (2): Conv1d(64, 64, kernel_size=(3,), stride=(2,))\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (linear): Sequential(\n",
       "    (0): Linear(in_features=3776, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "  )\n",
       "  (de_fc1): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=4096, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (de_conv): Sequential(\n",
       "    (0): ConvTranspose1d(128, 64, kernel_size=(3,), stride=(2,), padding=(2,))\n",
       "    (1): ConvTranspose1d(64, 32, kernel_size=(3,), stride=(2,), padding=(2,))\n",
       "    (2): ConvTranspose1d(32, 1, kernel_size=(3,), stride=(2,), padding=(2,))\n",
       "  )\n",
       "  (adjust_linear): Sequential(\n",
       "    (0): Linear(in_features=235, out_features=241, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('device, ',device)\n",
    "model = Generator()\n",
    "\n",
    "# lsgan  L1:0.1167\n",
    "# model_path = \"/home/ray/subt-analyze/09-mmwave-cGAN/generate_lidar/wandb/run-20200827_181923-2ikdkpzj/model.pth\"\n",
    "\n",
    "# bce logits loss L1:0.1163\n",
    "model_path = '/home/ray/subt-analyze/09-mmwave-cGAN/generate_lidar/wandb/run-20200827_185124-1wnumweh/model.pth'\n",
    "\n",
    "# patched lsgan L1: 0.1631\n",
    "# model_path = '/home/ray/subt-analyze/09-mmwave-cGAN/generate_lidar/wandb/run-20200828_153610-1x2nrzhi/model.pth'\n",
    "\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 582/582 [00:01<00:00, 506.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " corridor L1: 0.0948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "L1 = []\n",
    "t = tqdm(loader_corridor)\n",
    "for mm_scan, laser_scan in t:\n",
    "    mm_scan = mm_scan.to(device)\n",
    "    \n",
    "    x_hat = model(mm_scan)\n",
    "    x_hat = x_hat.detach().cpu()\n",
    "    \n",
    "    L1.append(l1(laser_scan,x_hat))\n",
    "    \n",
    "print(\"\\n corridor L1: %.4f\"%np.mean(L1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [00:00<00:00, 374.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " parking L1: 0.1114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "L1 = []\n",
    "t = tqdm(loader_parking)\n",
    "for mm_scan, laser_scan in t:\n",
    "    mm_scan = mm_scan.to(device)\n",
    "    \n",
    "    x_hat = model(mm_scan)\n",
    "    x_hat = x_hat.detach().cpu()\n",
    "    \n",
    "    L1.append(l1(laser_scan,x_hat))\n",
    "\n",
    "    \n",
    "print(\"\\n parking L1: %.4f\"%np.mean(L1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
