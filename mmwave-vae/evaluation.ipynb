{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import cv2\n",
    "import copy\n",
    "import math\n",
    "import wandb\n",
    "import random\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from collections import deque\n",
    "from tqdm import tqdm, trange\n",
    "from typing import Deque, Dict, List, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153 episodes\n",
      "31 episodes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "name_corridor = ['0717_1411', \n",
    "                '0720_1129',\n",
    "                '0722_1428',\n",
    "                '0722_1437',\n",
    "                '0722_1448',\n",
    "                '0722_1500',\n",
    "                '0722_1506',\n",
    "                '0722_1510',\n",
    "                '0722_1514',\n",
    "                '0724_1101',\n",
    "                '0724_1132',\n",
    "                '0724_1204',\n",
    "                '0727_1005',\n",
    "                '0727_1027',\n",
    "                '0727_1102',\n",
    "                '0727_1435',\n",
    "                '0727_1452',\n",
    "                '0727_1510',\n",
    "                '0727_1520',\n",
    "                '0805_1108',\n",
    "                '0805_1127',\n",
    "                '0805_1147']\n",
    "\n",
    "name_parking = ['0717_1504',\n",
    "                '0720_1105',\n",
    "                '0805_1349',\n",
    "                '0805_1425']\n",
    "\n",
    "paths_corridor, paths_parking = [], []\n",
    "\n",
    "main_path = '/media/ray/intelSSD/mmdemo_train'\n",
    "dirs = os.listdir(main_path)\n",
    "dirs.sort()\n",
    "for d in dirs:\n",
    "    dirs1 = os.listdir(main_path+'/'+d)\n",
    "    dirs1.sort()\n",
    "    dirs2 = os.listdir(main_path+'/'+d+'/'+dirs1[1])\n",
    "    dirs2.sort()\n",
    "    for d2 in dirs2:\n",
    "        if any(s in d2 for s in name_corridor):\n",
    "            paths_corridor.append(main_path+'/'+d+'/'+dirs1[1]+'/'+d2)\n",
    "#             print(paths_corridor[-1])\n",
    "        elif any(s in d2 for s in name_parking):\n",
    "            paths_parking.append(main_path+'/'+d+'/'+dirs1[1]+'/'+d2)\n",
    "#             print(paths_parking[-1])\n",
    "            \n",
    "print('%d episodes'%len(paths_corridor))\n",
    "print('%d episodes'%len(paths_parking))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153/153 [00:01<00:00, 90.26it/s]\n",
      "100%|██████████| 31/31 [00:00<00:00, 95.11it/s]\n"
     ]
    }
   ],
   "source": [
    "class MMDataset(Dataset):\n",
    "    def __init__(self, paths):\n",
    "        self.transitions = []\n",
    "\n",
    "        for p in tqdm(paths):\n",
    "            with open(p, \"rb\") as f:\n",
    "                demo = pkl.load(f, encoding=\"bytes\")\n",
    "                self.transitions.extend(demo)\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        mm_scan = self.transitions[index][b'mm_scan']\n",
    "        laser_scan = self.transitions[index][b'laser_scan']\n",
    "        mm_scan = torch.Tensor(mm_scan).reshape(1,-1)\n",
    "        laser_scan = torch.Tensor(laser_scan).reshape(1,-1)\n",
    "        \n",
    "        return mm_scan, laser_scan\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.transitions)\n",
    "\n",
    "    \n",
    "batch_size = 128\n",
    "\n",
    "corridor_dataset = MMDataset(paths_corridor)\n",
    "loader_corridor = DataLoader(dataset=corridor_dataset,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    num_workers=4)\n",
    "\n",
    "parking_dataset = MMDataset(paths_parking)\n",
    "loader_parking = DataLoader(dataset=parking_dataset,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    num_workers=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_parameter = dict(\n",
    "    kernel=3,\n",
    "    stride=2,\n",
    "    padding=2,\n",
    "    latent=128,\n",
    "    deconv_dim=32,\n",
    "    deconv_channel=128,\n",
    "    adjust_linear=235,\n",
    "    epoch=100,\n",
    "    learning_rate=0.001,\n",
    ")\n",
    "class Struct:\n",
    "    def __init__(self, **entries):\n",
    "        self.__dict__.update(entries)\n",
    "config = Struct(**hyper_parameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MMvae(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MMvae, self).__init__()\n",
    "        kernel = 3\n",
    "        stride = 2\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(1, 64, kernel_size=kernel, stride=stride),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 64, kernel_size=kernel, stride=stride),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        dim = 64*59\n",
    "        self.linear1=nn.Sequential(\n",
    "            nn.Linear(dim,512),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.en_fc1=nn.Linear(512,config.latent)\n",
    "        self.en_fc2=nn.Linear(512,config.latent)\n",
    "        \n",
    "        self.de_fc1=nn.Sequential(\n",
    "            nn.Linear(config.latent,config.deconv_channel*config.deconv_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.de_conv =nn.Sequential(\n",
    "            nn.ConvTranspose1d(config.deconv_channel, config.deconv_channel//2, kernel, stride=stride, padding=config.padding),\n",
    "#             nn.ReLU(),\n",
    "            nn.ConvTranspose1d(config.deconv_channel//2, config.deconv_channel//4, kernel, stride=stride, padding=config.padding),\n",
    "#             nn.ReLU(),\n",
    "            nn.ConvTranspose1d(config.deconv_channel//4, 1, kernel, stride=stride, padding=config.padding),\n",
    "#             nn.ReLU(),\n",
    "        )\n",
    "        self.adjust_linear=nn.Sequential(\n",
    "            nn.Linear(config.adjust_linear,241),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        \n",
    "    def encoder(self,x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.linear1(x)\n",
    "        mean = self.en_fc1(x)\n",
    "        logvar = self.en_fc2(x)\n",
    "        return mean, logvar\n",
    "\n",
    "    def reparameter(self, mean, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mean + eps*std\n",
    "\n",
    "    def decoder(self,x):\n",
    "        x = self.de_fc1(x)\n",
    "        x = x.view(-1, config.deconv_channel, config.deconv_dim)\n",
    "        x = self.de_conv(x)\n",
    "        x = self.adjust_linear(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self,x):\n",
    "        mean, logvar = self.encoder(x)\n",
    "        x = self.reparameter(mean, logvar)\n",
    "        x = self.decoder(x)\n",
    "        return x ,mean ,logvar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device,  cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('device, ',device)\n",
    "model = MMvae()\n",
    "model.to(device)\n",
    "model_path = \"/home/ray/subt-analyze/07-mmwave-vae/generate_lidar/wandb/run-20200726_155759-3235857x/model.pth\"\n",
    "model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 582/582 [00:01<00:00, 475.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " corridor L1: 0.2315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "L1 = []\n",
    "t = tqdm(loader_corridor)\n",
    "for mm_scan, laser_scan in t:\n",
    "    mm_scan = mm_scan.to(device)\n",
    "    \n",
    "    x_hat ,mean ,logvar = model(mm_scan)\n",
    "    x_hat = x_hat.detach().cpu().numpy().reshape(mm_scan.size(0),-1)\n",
    "    laser_scan = laser_scan.numpy().reshape(mm_scan.size(0),-1)\n",
    "    mm_scan = mm_scan.detach().cpu().numpy().reshape(mm_scan.size(0),-1)\n",
    "    \n",
    "    l1 = np.mean(np.abs(laser_scan-x_hat))\n",
    "    L1.append(l1)\n",
    "    \n",
    "print(\"\\n corridor L1: %.4f\"%np.mean(L1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [00:00<00:00, 374.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " parking L1: 0.2722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "L1 = []\n",
    "t = tqdm(loader_parking)\n",
    "for mm_scan, laser_scan in t:\n",
    "    mm_scan = mm_scan.to(device)\n",
    "    \n",
    "    x_hat ,mean ,logvar = model(mm_scan)\n",
    "    x_hat = x_hat.detach().cpu().numpy().reshape(mm_scan.size(0),-1)\n",
    "    laser_scan = laser_scan.numpy().reshape(mm_scan.size(0),-1)\n",
    "    mm_scan = mm_scan.detach().cpu().numpy().reshape(mm_scan.size(0),-1)\n",
    "    \n",
    "    l1 = np.mean(np.abs(laser_scan-x_hat))\n",
    "    L1.append(l1)\n",
    "    \n",
    "print(\"\\n parking L1: %.4f\"%np.mean(L1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
